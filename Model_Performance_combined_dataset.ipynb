{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae366eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Add, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "from sklearn.metrics import (mean_squared_error,\n",
    "                           r2_score,\n",
    "                           mean_absolute_error,\n",
    "                           explained_variance_score)\n",
    "\n",
    "from tensorflow.keras.layers import (Dense, Dropout, BatchNormalization,\n",
    "                                   Input, Concatenate, Reshape, Conv1D,\n",
    "                                   MaxPooling1D, Flatten, MultiHeadAttention,\n",
    "                                   LayerNormalization, GlobalAveragePooling1D,\n",
    "                                   Embedding, Add, Attention)\n",
    "\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau,\n",
    "                                      ModelCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b08fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Additive concentration</th>\n",
       "      <th>MAI</th>\n",
       "      <th>FAI</th>\n",
       "      <th>CsI</th>\n",
       "      <th>CsBr</th>\n",
       "      <th>MABr</th>\n",
       "      <th>MACl</th>\n",
       "      <th>PbI2</th>\n",
       "      <th>PbBr2</th>\n",
       "      <th>PbCl2</th>\n",
       "      <th>...</th>\n",
       "      <th>DMF</th>\n",
       "      <th>DMSO</th>\n",
       "      <th>GBL</th>\n",
       "      <th>Polarity index</th>\n",
       "      <th>Annealing tem</th>\n",
       "      <th>Etl</th>\n",
       "      <th>Htl</th>\n",
       "      <th>Back contact</th>\n",
       "      <th>Interlayer</th>\n",
       "      <th>PCE (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Additive concentration  MAI  FAI  CsI  CsBr  MABr  MACl  PbI2  PbBr2  \\\n",
       "0                     0.0  0.0  0.4  0.0   0.0   0.0   0.0   0.0    0.0   \n",
       "1                     0.0  0.0  0.4  0.0   0.0   0.0   0.0   0.0    0.0   \n",
       "2                     0.0  0.0  0.4  0.0   0.0   0.0   0.0   0.0    0.0   \n",
       "3                     0.0  0.0  0.4  0.0   0.0   0.0   0.0   0.0    0.0   \n",
       "4                     0.0  0.0  0.4  0.0   0.0   0.0   0.0   0.0    0.0   \n",
       "\n",
       "   PbCl2  ...  DMF  DMSO  GBL  Polarity index  Annealing tem  Etl  Htl  \\\n",
       "0    0.0  ...  0.8   0.2  0.0             2.7            1.0  6.0  8.0   \n",
       "1    0.0  ...  0.8   0.2  0.0             2.7            1.0  6.0  8.0   \n",
       "2    0.0  ...  0.8   0.2  0.0             2.7            1.0  6.0  8.0   \n",
       "3    0.0  ...  0.8   0.2  0.0             2.7            1.0  6.0  8.0   \n",
       "4    0.0  ...  0.8   0.2  0.0             2.7            1.0  6.0  8.0   \n",
       "\n",
       "   Back contact  Interlayer  PCE (%)  \n",
       "0           1.0         2.0    5.200  \n",
       "1           1.0         2.0    4.828  \n",
       "2           1.0         2.0    4.836  \n",
       "3           1.0         2.0    5.070  \n",
       "4           1.0         2.0    4.980  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('generated_data_and_train_dataset.xlsx')\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d023871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additive concentration    0\n",
      "MAI                       0\n",
      "FAI                       0\n",
      "CsI                       0\n",
      "CsBr                      0\n",
      "MABr                      0\n",
      "MACl                      0\n",
      "PbI2                      0\n",
      "PbBr2                     0\n",
      "PbCl2                     0\n",
      "SnI2                      0\n",
      "SnCl2                     0\n",
      "SnBr2                     0\n",
      "Pb(SCN)2                  0\n",
      "SnF2                      0\n",
      "DMF                       0\n",
      "DMSO                      0\n",
      "GBL                       0\n",
      "Polarity index            0\n",
      "Annealing tem             0\n",
      "Etl                       0\n",
      "Htl                       0\n",
      "Back contact              0\n",
      "Interlayer                0\n",
      "PCE (%)                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab0db323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5390, 24) (5390,)\n"
     ]
    }
   ],
   "source": [
    "X_train = df.drop(['PCE (%)'], axis= 1)\n",
    "y_train = df['PCE (%)']\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5f7c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Additive concentration</th>\n",
       "      <th>MAI</th>\n",
       "      <th>FAI</th>\n",
       "      <th>CsI</th>\n",
       "      <th>CsBr</th>\n",
       "      <th>MABr</th>\n",
       "      <th>MACl</th>\n",
       "      <th>PbI2</th>\n",
       "      <th>PbBr2</th>\n",
       "      <th>PbCl2</th>\n",
       "      <th>...</th>\n",
       "      <th>DMF</th>\n",
       "      <th>DMSO</th>\n",
       "      <th>GBL</th>\n",
       "      <th>Polarity index</th>\n",
       "      <th>Annealing tem</th>\n",
       "      <th>Etl</th>\n",
       "      <th>Htl</th>\n",
       "      <th>Back contact</th>\n",
       "      <th>Interlayer</th>\n",
       "      <th>PCE (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Additive concentration   MAI  FAI  CsI  CsBr  MABr  MACl  PbI2  PbBr2  \\\n",
       "0                       0  1.47  0.0  0.0   0.0   0.0   0.0  1.47    0.0   \n",
       "1                       2  1.47  0.0  0.0   0.0   0.0   0.0  1.47    0.0   \n",
       "2                       4  1.47  0.0  0.0   0.0   0.0   0.0  1.47    0.0   \n",
       "3                       5  1.47  0.0  0.0   0.0   0.0   0.0  1.47    0.0   \n",
       "4                       0  2.00  0.0  0.0   0.0   0.0   0.0  0.50    0.0   \n",
       "\n",
       "   PbCl2  ...   DMF  DMSO  GBL  Polarity index  Annealing tem  Etl  Htl  \\\n",
       "0    0.0  ...  0.88  0.12  0.0             2.4            1.0    2    4   \n",
       "1    0.0  ...  0.88  0.12  0.0             2.4            1.0    2    4   \n",
       "2    0.0  ...  0.88  0.12  0.0             2.4            1.0    2    4   \n",
       "3    0.0  ...  0.88  0.12  0.0             2.4            1.0    2    4   \n",
       "4    0.5  ...  1.00  0.00  0.0             0.0            1.1    3    8   \n",
       "\n",
       "   Back contact  Interlayer  PCE (%)  \n",
       "0             0           0    16.23  \n",
       "1             0           0    17.14  \n",
       "2             0           0    18.22  \n",
       "3             0           0    16.80  \n",
       "4             2           0    14.00  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_excel('151_test_data.xlsx')\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86bba474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additive concentration    0\n",
      "MAI                       0\n",
      "FAI                       0\n",
      "CsI                       0\n",
      "CsBr                      0\n",
      "MABr                      0\n",
      "MACl                      0\n",
      "PbI2                      0\n",
      "PbBr2                     0\n",
      "PbCl2                     0\n",
      "SnI2                      0\n",
      "SnCl2                     0\n",
      "SnBr2                     0\n",
      "Pb(SCN)2                  0\n",
      "SnF2                      0\n",
      "DMF                       0\n",
      "DMSO                      0\n",
      "GBL                       0\n",
      "Polarity index            0\n",
      "Annealing tem             0\n",
      "Etl                       0\n",
      "Htl                       0\n",
      "Back contact              0\n",
      "Interlayer                0\n",
      "PCE (%)                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d33ee75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151, 24) (151,)\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df.drop(['PCE (%)'], axis= 1)\n",
    "y_test = test_df['PCE (%)']\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a83af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59cf319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(y_true, y_pred):\n",
    "    SS_res = K.sum(K.square(y_true - y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c49ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_nn():\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='swish', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dense(32, activation='swish'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Nadam(0.001), loss='mean_squared_error', metrics=['mae', r_squared])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c02e0ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deep_nn():\n",
    "    model = Sequential([\n",
    "      Dense(192, activation='swish', kernel_initializer=HeNormal(), input_shape=(X_train_scaled.shape[1],)),\n",
    "      BatchNormalization(),\n",
    "      Dense(96, activation='swish', kernel_initializer=HeNormal()),\n",
    "      BatchNormalization(),\n",
    "      Dense(48, activation='swish', kernel_initializer=HeNormal()),\n",
    "      BatchNormalization(),\n",
    "      Dense(1)\n",
    "  ])\n",
    "    model.compile(optimizer=Adam(0.0005), loss='mean_squared_error', metrics=['mae', r_squared])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd90f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_residual_nn():\n",
    "    inputs = Input(shape=(X_train_scaled.shape[1],))\n",
    "    x = Dense(256, activation='swish')(inputs)  \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1)(x)  \n",
    "    # Residual block 1\n",
    "    residual = x\n",
    "    x = Dense(256)(x)  \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('swish')(x)\n",
    "    x = Dense(256)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, residual])\n",
    "    x = Activation('swish')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    # Residual block 2 \n",
    "    residual = Dense(128, use_bias=False)(x) if x.shape[-1] != 128 else x  \n",
    "    x = Dense(128)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('swish')(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, residual])\n",
    "    x = Activation('swish')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    # Residual block 3 \n",
    "    residual = Dense(64, use_bias=False)(x) if x.shape[-1] != 64 else x\n",
    "    x = Dense(64)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('swish')(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, residual])\n",
    "    x = Activation('swish')(x)\n",
    "\n",
    "    outputs = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(0.0001), loss='mean_squared_error', metrics=['mae', r_squared]) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "772cb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn():\n",
    "    model = Sequential([\n",
    "        Reshape((X_train_scaled.shape[1], 1), input_shape=(X_train_scaled.shape[1],)),\n",
    "        Conv1D(64, 3, activation='swish', padding='same'),\n",
    "        MaxPooling1D(2),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(128, 3, activation='swish', padding='same'),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(64, activation='swish'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Nadam(0.001), loss='mean_squared_error', metrics=['mae', r_squared])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6bafceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wide_deep():\n",
    "    inputs = Input(shape=(X_train_scaled.shape[1],))\n",
    "\n",
    "    # Wide Path\n",
    "    wide = Dense(32, activation='linear')(inputs)\n",
    "\n",
    "    # Deep Path\n",
    "    deep = Dense(128, activation='swish')(inputs)\n",
    "    deep = BatchNormalization()(deep)\n",
    "    deep = Dropout(0.3)(deep)\n",
    "    deep = Dense(64, activation='swish')(deep)\n",
    "\n",
    "    # Concatenate\n",
    "    merged = Concatenate()([wide, deep])\n",
    "    outputs = Dense(1)(merged)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(0.0005), loss='mean_squared_error', metrics=['mae', r_squared])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af863e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tab_transformer():\n",
    "    inputs = Input(shape=(X_train_scaled.shape[1],))\n",
    "\n",
    "    #Feature Projection\n",
    "    x = Dense(256, activation='swish', kernel_initializer='he_normal')(inputs)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Reshape((16, 16))(x)\n",
    "\n",
    "    #Transformer Encoder Blocks\n",
    "    for _ in range(2):\n",
    "\n",
    "        residual = x\n",
    "\n",
    "        #Multi-Head Attention\n",
    "        attn_output = MultiHeadAttention(\n",
    "            num_heads=4,         \n",
    "            key_dim=4,            \n",
    "            dropout=0.1\n",
    "        )(x, x)\n",
    "\n",
    "\n",
    "        if residual.shape[-1] != attn_output.shape[-1]:\n",
    "            residual = Dense(attn_output.shape[-1])(residual)\n",
    "\n",
    "\n",
    "        x = LayerNormalization()(residual + attn_output)\n",
    "\n",
    "        #Feed Forward Network\n",
    "        ffn = Dense(64, activation='swish')(x)  \n",
    "        ffn = Dropout(0.1)(ffn)\n",
    "        ffn = Dense(16)(ffn)  \n",
    "\n",
    "        x = LayerNormalization()(x + ffn)\n",
    "\n",
    "    #Classification Head\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='swish')(x)\n",
    "    outputs = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss=Huber(),\n",
    "        metrics=['mae', r_squared]\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce36dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_attention_nn():\n",
    "\n",
    "    inputs = Input(shape=(X_train_scaled.shape[1],))\n",
    "\n",
    "    \n",
    "    x = Dense(512, activation='swish', kernel_initializer='he_normal')(inputs)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    \n",
    "    x = Reshape((16, 32))(x)  \n",
    "\n",
    "    #Self-Attention with residual connection\n",
    "    attn_output = MultiHeadAttention(\n",
    "        num_heads=8,\n",
    "        key_dim=16,\n",
    "        dropout=0.3,\n",
    "        kernel_regularizer=l1_l2(1e-5, 1e-4)\n",
    "    )(x, x)\n",
    "    x = LayerNormalization()(x + attn_output)\n",
    "\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='swish', kernel_initializer='he_normal')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(128, activation='swish')(x)\n",
    "    outputs = Dense(1)(x)\n",
    "\n",
    "    \n",
    "    optimizer = Nadam(learning_rate=0.00005, clipnorm=1.0)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=Huber(delta=1.0),  \n",
    "        metrics=['mae', r_squared]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "852b5a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classic_models\n",
    "\n",
    "classic_models = {\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=200, max_depth=10,\n",
    "                                         min_samples_split=5, random_state=42),\n",
    "\n",
    "    'XGBoost':   XGBRegressor(\n",
    "                    objective='reg:squarederror',\n",
    "                    n_estimators=100,\n",
    "                    max_depth=6,\n",
    "                    learning_rate=0.1,\n",
    "                    random_state=42),\n",
    "\n",
    "    'GBoost' :   GradientBoostingRegressor(\n",
    "                  n_estimators=100,\n",
    "                  max_depth=6,\n",
    "                  learning_rate=0.1,\n",
    "                  random_state=42),\n",
    "\n",
    "\n",
    "\n",
    "    'DTree': DecisionTreeRegressor(max_depth=10, min_samples_split=5, random_state=42),\n",
    "    'ETree': ExtraTreesRegressor(n_estimators=200, max_depth=10,\n",
    "                                min_samples_split=5, random_state=42),\n",
    "    'ABoost': AdaBoostRegressor(n_estimators=200, learning_rate=0.05, random_state=42),\n",
    "    'SVM': SVR(kernel='rbf', C=1.0, epsilon=0.1),\n",
    "    \n",
    "\n",
    "    \n",
    "    'MLP': MLPRegressor(hidden_layer_sizes=(100,50), activation='relu',\n",
    "                       solver='adam', alpha=0.0001, batch_size='auto',\n",
    "                       learning_rate='constant', learning_rate_init=0.001,\n",
    "                       max_iter=200, random_state=42)\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecd430db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:38: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#NN_models\n",
    "\n",
    "nn_models = {\n",
    "    'Simple NN': build_simple_nn(),\n",
    "    'Deep NN': build_deep_nn(),\n",
    "    'Residual NN': build_residual_nn(),\n",
    "    'Attention NN': build_attention_nn(),\n",
    "    '1D CNN': build_1d_cnn(),\n",
    "    'Wide & Deep': build_wide_deep(),\n",
    "    'tab-transformer': build_tab_transformer(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51733b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "def get_callbacks(name):\n",
    "    return [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n",
    "        ModelCheckpoint(f'best_{name}.keras', save_best_only=True)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6e0794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Random Forest\n",
      "Train RMSE: 0.9124\n",
      "Train MAE: 0.6275\n",
      "Train R2: 0.9730\n",
      "Train Explained Variance: 0.9730\n",
      "Test RMSE: 2.2631\n",
      "Test MAE: 1.6580\n",
      "Test R2: 0.8018\n",
      "Test Explained Variance: 0.8190\n",
      "\n",
      "Model: XGBoost\n",
      "Train RMSE: 0.8009\n",
      "Train MAE: 0.5318\n",
      "Train R2: 0.9792\n",
      "Train Explained Variance: 0.9792\n",
      "Test RMSE: 1.7726\n",
      "Test MAE: 1.3922\n",
      "Test R2: 0.8784\n",
      "Test Explained Variance: 0.8914\n",
      "\n",
      "Model: GBoost\n",
      "Train RMSE: 0.7599\n",
      "Train MAE: 0.5157\n",
      "Train R2: 0.9813\n",
      "Train Explained Variance: 0.9813\n",
      "Test RMSE: 1.9674\n",
      "Test MAE: 1.5175\n",
      "Test R2: 0.8502\n",
      "Test Explained Variance: 0.8688\n",
      "\n",
      "Model: DTree\n",
      "Train RMSE: 1.0356\n",
      "Train MAE: 0.6927\n",
      "Train R2: 0.9652\n",
      "Train Explained Variance: 0.9652\n",
      "Test RMSE: 3.1593\n",
      "Test MAE: 2.0995\n",
      "Test R2: 0.6137\n",
      "Test Explained Variance: 0.6380\n",
      "\n",
      "Model: ETree\n",
      "Train RMSE: 1.1497\n",
      "Train MAE: 0.8090\n",
      "Train R2: 0.9571\n",
      "Train Explained Variance: 0.9571\n",
      "Test RMSE: 1.8641\n",
      "Test MAE: 1.3699\n",
      "Test R2: 0.8655\n",
      "Test Explained Variance: 0.8822\n",
      "\n",
      "Model: ABoost\n",
      "Train RMSE: 2.4265\n",
      "Train MAE: 1.9247\n",
      "Train R2: 0.8089\n",
      "Train Explained Variance: 0.8117\n",
      "Test RMSE: 3.1686\n",
      "Test MAE: 2.5017\n",
      "Test R2: 0.6114\n",
      "Test Explained Variance: 0.7596\n",
      "\n",
      "Model: SVM\n",
      "Train RMSE: 1.6591\n",
      "Train MAE: 1.0104\n",
      "Train R2: 0.9106\n",
      "Train Explained Variance: 0.9111\n",
      "Test RMSE: 2.9769\n",
      "Test MAE: 2.1631\n",
      "Test R2: 0.6570\n",
      "Test Explained Variance: 0.6746\n",
      "\n",
      "Model: MLP\n",
      "Train RMSE: 0.8684\n",
      "Train MAE: 0.5683\n",
      "Train R2: 0.9755\n",
      "Train Explained Variance: 0.9755\n",
      "Test RMSE: 2.6271\n",
      "Test MAE: 2.0420\n",
      "Test R2: 0.7329\n",
      "Test Explained Variance: 0.7357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Classic_training\n",
    "\n",
    "for name, model in classic_models.items():\n",
    "\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    train_metrics = {\n",
    "        'Train RMSE': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        'Train MAE': mean_absolute_error(y_train, y_train_pred),\n",
    "        'Train R2': r2_score(y_train, y_train_pred),\n",
    "        'Train Explained Variance': explained_variance_score(y_train, y_train_pred)\n",
    "    }\n",
    "\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    test_metrics = {\n",
    "        'Test RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        'Test MAE': mean_absolute_error(y_test, y_test_pred),\n",
    "        'Test R2': r2_score(y_test, y_test_pred),\n",
    "        'Test Explained Variance': explained_variance_score(y_test, y_test_pred)\n",
    "    }\n",
    "\n",
    "    results[name] = {**train_metrics, **test_metrics}\n",
    "\n",
    "\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    for metric, value in results[name].items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=y_test, y=y_test_pred)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title(f'{name} - Actual vs Predicted')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{name}_actual_vs_predicted.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98f18502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\n",
      "Model: Simple NN\n",
      "Train RMSE: 1.0708\n",
      "Train MAE: 0.7295\n",
      "Train R2: 0.9628\n",
      "Train Explained Variance: 0.9628\n",
      "Test RMSE: 2.5942\n",
      "Test MAE: 1.9323\n",
      "Test R2: 0.7395\n",
      "Test Explained Variance: 0.7404\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Model: Deep NN\n",
      "Train RMSE: 1.2081\n",
      "Train MAE: 0.8545\n",
      "Train R2: 0.9526\n",
      "Train Explained Variance: 0.9527\n",
      "Test RMSE: 2.0614\n",
      "Test MAE: 1.6307\n",
      "Test R2: 0.8355\n",
      "Test Explained Variance: 0.8403\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\n",
      "Model: Residual NN\n",
      "Train RMSE: 1.2421\n",
      "Train MAE: 0.8529\n",
      "Train R2: 0.9499\n",
      "Train Explained Variance: 0.9533\n",
      "Test RMSE: 1.9496\n",
      "Test MAE: 1.6036\n",
      "Test R2: 0.8529\n",
      "Test Explained Variance: 0.8548\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\n",
      "Model: Attention NN\n",
      "Train RMSE: 1.9618\n",
      "Train MAE: 1.3854\n",
      "Train R2: 0.8751\n",
      "Train Explained Variance: 0.8866\n",
      "Test RMSE: 2.3336\n",
      "Test MAE: 1.7717\n",
      "Test R2: 0.7892\n",
      "Test Explained Variance: 0.8044\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\n",
      "Model: 1D CNN\n",
      "Train RMSE: 1.5076\n",
      "Train MAE: 1.0659\n",
      "Train R2: 0.9262\n",
      "Train Explained Variance: 0.9262\n",
      "Test RMSE: 2.0629\n",
      "Test MAE: 1.6611\n",
      "Test R2: 0.8353\n",
      "Test Explained Variance: 0.8358\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\n",
      "Model: Wide & Deep\n",
      "Train RMSE: 1.3746\n",
      "Train MAE: 0.9510\n",
      "Train R2: 0.9387\n",
      "Train Explained Variance: 0.9387\n",
      "Test RMSE: 1.9855\n",
      "Test MAE: 1.5663\n",
      "Test R2: 0.8474\n",
      "Test Explained Variance: 0.8482\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\n",
      "Model: tab-transformer\n",
      "Train RMSE: 1.7300\n",
      "Train MAE: 1.1353\n",
      "Train R2: 0.9028\n",
      "Train Explained Variance: 0.9102\n",
      "Test RMSE: 2.4599\n",
      "Test MAE: 1.8645\n",
      "Test R2: 0.7658\n",
      "Test Explained Variance: 0.7676\n"
     ]
    }
   ],
   "source": [
    "#NN_training\n",
    "\n",
    "for name, model in nn_models.items():\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=get_callbacks(name),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    y_train_pred = model.predict(X_train_scaled).flatten()\n",
    "    train_metrics = {\n",
    "        'Train RMSE': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        'Train MAE': mean_absolute_error(y_train, y_train_pred),\n",
    "        'Train R2': r2_score(y_train, y_train_pred),\n",
    "        'Train Explained Variance': explained_variance_score(y_train, y_train_pred)\n",
    "    }\n",
    "\n",
    "    y_test_pred = model.predict(X_test_scaled).flatten()\n",
    "    test_metrics = {\n",
    "        'Test RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        'Test MAE': mean_absolute_error(y_test, y_test_pred),\n",
    "        'Test R2': r2_score(y_test, y_test_pred),\n",
    "        'Test Explained Variance': explained_variance_score(y_test, y_test_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "    results[name] = {**train_metrics, **test_metrics}\n",
    "    \n",
    "    print(f\"\\nModel: {name}\")\n",
    "    for metric, value in results[name].items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    ax1.plot(history.history['loss'], label='Train Loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_title(f'{name} - Learning Curve')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['r_squared'], label='Train R²')\n",
    "    ax2.plot(history.history['val_r_squared'], label='Validation R²')\n",
    "    ax2.set_title(f'{name} - R² Score')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('R²')\n",
    "    ax2.legend()\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=y_test_pred, ax=ax3)\n",
    "    ax3.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "    ax3.set_xlabel('Actual Values')\n",
    "    ax3.set_ylabel('Predicted Values')\n",
    "    ax3.set_title(f'{name} - Actual vs Predicted')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{name}_performance.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf7bcdff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).T\n",
    "results_df[['Test RMSE', 'Test R2', 'Test MAE']].sort_values(by='Test R2', ascending=False).head(7)\n",
    "\n",
    "results_df = results_df.sort_values(by='Test RMSE')\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "results_df['Test RMSE'].sort_values().plot(kind='barh')\n",
    "plt.title('Model Comparison by Test RMSE (Lower is Better)')\n",
    "plt.xlabel('RMSE')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c28e8cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Models by Test R2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Residual NN</th>\n",
       "      <td>1.949594</td>\n",
       "      <td>0.852887</td>\n",
       "      <td>1.603586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wide &amp; Deep</th>\n",
       "      <td>1.985454</td>\n",
       "      <td>0.847426</td>\n",
       "      <td>1.566290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep NN</th>\n",
       "      <td>2.061441</td>\n",
       "      <td>0.835524</td>\n",
       "      <td>1.630666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1D CNN</th>\n",
       "      <td>2.062940</td>\n",
       "      <td>0.835284</td>\n",
       "      <td>1.661120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attention NN</th>\n",
       "      <td>2.333621</td>\n",
       "      <td>0.789223</td>\n",
       "      <td>1.771679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tab-transformer</th>\n",
       "      <td>2.459946</td>\n",
       "      <td>0.765786</td>\n",
       "      <td>1.864481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Simple NN</th>\n",
       "      <td>2.594204</td>\n",
       "      <td>0.739523</td>\n",
       "      <td>1.932346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Test RMSE   Test R2  Test MAE\n",
       "Residual NN       1.949594  0.852887  1.603586\n",
       "Wide & Deep       1.985454  0.847426  1.566290\n",
       "Deep NN           2.061441  0.835524  1.630666\n",
       "1D CNN            2.062940  0.835284  1.661120\n",
       "Attention NN      2.333621  0.789223  1.771679\n",
       "tab-transformer   2.459946  0.765786  1.864481\n",
       "Simple NN         2.594204  0.739523  1.932346"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nTop Models by Test R2:\")\n",
    "results_df[['Test RMSE', 'Test R2', 'Test MAE']].sort_values(by='Test R2', ascending=False).head(7)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
